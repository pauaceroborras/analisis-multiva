#PREREQUISITES: 
#factors are properly labelled and reading data makes R to directly recognize them
#Numerical variables do not contain missing values anymore. They have been imputed in preprocessing step

#  READING CREDSCO_BIN
# load("d:/karina/docencia/sreferenciesppt/16.AssociatiusVisualitzacio/MultivariateAnalysis/PracticaR/credscok_bin")
setwd("D:/karina/docencia/01areferenciesPPT/0DadesPractiques/CREDSCO")
#dd <- read.table("credscoClean.csv",header=T, sep=";");

library(FactoMineR)
iris <- dadesfinals
PCAres <- PCA(iris, quali.sup = c(1, 2, 4, 5, 7, 11, 13), graph = FALSE)

PCAres$eig

nc <- 5

dadesClust <- PCAres$ind$coord
Distancias <- dist(dadesClust)
cluster <- hclust(Distancias, method = "ward.D2")
plot(cluster)

clut <- 6
clases <- cutree(cluster, k = 6)

iris$cluster <- factor(clases)

# ==============================================================================
# Carreguem les llibreries necessaris
list.of.packages <-c("caret", "MASS", "klaR", "ggplot2", "ggpubr") 
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages) > 0) {
  install.packages(new.packages)
}
lapply(list.of.packages, require, character.only = T)
rm(list.of.packages, new.packages)

# ==============================================================================
# Carreguem les dades

head(iris)

# ------------------------------------------------------------------------------
# Dividim les dades: 80% entrenament i 20% test
## Declarem la semilla
set.seed(1994)

muestra <- caret::createDataPartition(y = iris[, "cluster"], p = 0.8, list = FALSE)
train <- iris[muestra, ]
test <- iris[-muestra, ]

# EstimaciÃ³ dels parÃ metres de preprocessament
preproc_param <- caret::preProcess(x = train, method = c("center", "scale"))

# Transformem les dades segons el que s'ha establert en els parÃ metres anteriors
train <- preproc_param |> predict(train)
test <- preproc_param |> predict(test)

# ==============================================================================
# Podem visualitzar les dades per poder detectar variables classificadores que 
# puguin contribuir a la discriminaciÃ³ dels grups
p1 <- ggplot(data = train, aes(x = Edat, fill = cluster, colour = cluster)) +
  geom_density(alpha = 0.3) +
  theme_bw()
p2 <- ggplot(data = train, aes(x = Distancia, fill = cluster, colour = cluster)) +
  geom_density(alpha = 0.3) +
  theme_bw()
p3 <- ggplot(data = train, aes(x = Menjar, fill = cluster, colour = cluster)) +
  geom_density(alpha = 0.3) +
  theme_bw()
p4 <- ggplot(data = train, aes(x = Comoditat, fill = cluster, colour = cluster)) +
  geom_density(alpha = 0.3) +
  theme_bw()
p5 <- ggplot(data = train, aes(x = Retard_sortida, fill = cluster, colour = cluster)) +
  geom_density(alpha = 0.3) +
  theme_bw()
p6 <- ggplot(data = train, aes(x = Diferencia_durada, fill = cluster, colour = cluster)) +
  geom_density(alpha = 0.3) +
  theme_bw()
p7 <- ggplot(data = train, aes(x = Embarcament, fill = cluster, colour = cluster)) +
  geom_density(alpha = 0.3) +
  theme_bw()
ggarrange(p1, p2, p3, p4,p5, p6, p7, ncol = 4, nrow = 2, common.legend = TRUE, legend = "bottom")

# ------------------------------------------------------------------------------
# TambÃ© ho podem veure visualitzant les grÃ fiques de punts per veure distÃ ncies als
# centroides
pairs(x = train[, -5], col = c("firebrick", "green3", "darkblue")[train[, 'cluster']], pch = 20)

## Como se observa en dichos grÃ¡ficos, las variables clasificadoras pueden contribuir 
## a la discriminaciÃ³n entre las tres especies de flores iris.
## Para aplicar la funciÃ³n lda() se debe especificar la variable de clasificaciÃ³n 
## (Species) y el conjunto de datos (entrenamiento_t); de forma opcional, se 
## pueden especificar las probabilidades a priori (prior, por defecto se usa 
## proportions), el mÃ©todo de estimaciÃ³n de las medias y varianzas (method, 
## por defecto moment) o el argumento CV para obtener los grupos pronosticados 
## y las probabilidades a posteriori (por defecto, CV=FALSE).

options(digits = 4)
modelo_lda <- lda(cluster ~ ., data = train)
modelo_lda

## La salida muestra las probabilidades previas (Prior probabilities of groups) 
## y los centroides de cada grupo (Group means). A continuaciÃ³n muestra las 
## funciones discriminantes de Fisher mediante los respectivos coeficientes w_jt
## En este caso, las dos funciones discriminantes son:
## D_1 = 0.6497Â·SL + 0.7416Â·SW - 3.9531Â·PL - 2.0670Â·PW
## D_2 = -0.1239Â·SL - 0.8131Â·SW + 2.0349Â·PL - 2.4184Â·PW
## con una proporciÃ³n de discriminaciÃ³n de 0,9927 y 0,0073, respectivamente.

## La proyecciÃ³n de los individuos (en este caso flores) en el plano formado por 
## las dos funciones discriminantes:

datos_lda <- cbind(train, predict(modelo_lda)$x)
ggplot(datos_lda, aes(LD1, LD2)) +
  geom_point(aes(color = cluster)) +
  ggtitle("GrÃ¡fico LDA")

## Como se aprecia, la primera funciÃ³n discriminante es la que mayor contribuciÃ³n 
## tiene a la separaciÃ³n entre los grupos, separando muy claramente a la especie 
## setosa y, en menor medida, a las especies virginica y versicolor, grupos entre 
## los que hay un pequeÃ±o grado de solapamiento. Por otro lado, la segunda funciÃ³n 
## discriminante, con una proporciÃ³n de discriminaciÃ³n de 0,0073, apenas contribuye a 
## la separaciÃ³n entre grupos.

## Por Ãºltimo, mediante la funciÃ³n partimat() del paquete klaR, se puede visualizar 
## cÃ³mo quedan las regiones bivariantes que clasifican los individuos en cada clase 


#HACER DUMMIES PARA QUE ENTREN LAS CATEGORICAS
train$Loyal  <- as.vector(model.matrix(~ Tipus_client, data = train)[,2])
#train$Disloyal <- ifelse(train$Loyal == 1, 0, 1)
train$Personal_travel <- as.vector(model.matrix(~ Tipus_viatge, data = train)[,2])
#train$Business_travel <- ifelse(train$Personal_travel == 1, 0, 1)
train$Eco <- as.vector(model.matrix(~ Classe_client, data = train)[,2])
train$Eco_plus <- as.vector(model.matrix(~ Classe_client, data = train)[,3])
#train$Business2 <- ifelse(train$Eco == 0 & train$Eco_plus == 0, 1, 0)
train$satisfied <- as.vector(model.matrix(~ Satsifaccio, data = train)[,2])
#train$Neutral_or_satisfied <- ifelse(train$satisfied == 0,1, 0)


png("grafico.png", width=8000, height=6000) # Cambia el tamaño según necesites

klaR::partimat(cluster ~ ., data = train[,c(3,6,8,9,10,12,14:20)], method = "lda", 
               image.colors = c("skyblue", "lightgrey", "yellow", "green", "pink", "navyblue"), col.mean = "red")
dev.off()


## Por Ãºltimo, aplicando las funciones discriminantes a los datos reservados para 
## estudiar la capacidad predictiva del modelo, se obtiene la tabla conocida como 
## matriz de confusiÃ³n, donde se compara el grupo real con el pronosticado por el 
## modelo:

predicciones_lda <- modelo_lda |> predict(test)
table(test$cluster, predicciones_lda$class, dnn = c("Grupo real", "Grupo pronosticado"))
mean(predicciones_lda$class == test$cluster)


# ==============================================================================
# ANALISIS DISCRIMINANT CUADRÃ€TIC
## Para ilustrar la realizaciÃ³n de un anÃ¡lisis discriminante cuadrÃ¡tico en R, se 
## aplica la funciÃ³n qda() a los datos iris utilizados en el caso lineal. 
## La elecciÃ³n de la misma base de datos responde a un planteamiento didÃ¡ctico, 
## para poder comparar los resultados de ambos mÃ©todos y las diferencias que produce 
## asumir la igualdad de matrices de varianzas-covarianzas (mÃ©todo lineal) o 
## no asumirlas (mÃ©todo cuadrÃ¡tico)

options(digits = 4)
modelo_qda <- qda(cluster ~ ., data = train)
modelo_qda

partimat(cluster ~ ., data = train, method = "qda", image.colors = c("skyblue", "lightgrey", "yellow"), col.mean = "red")

## Como se aprecia, ahora los contornos de las Ã¡reas no son siempre lineales, sino 
## que incluyen fronteras cuadrÃ¡ticas. Por Ãºltimo, aplicando el discriminante 
## cuadrÃ¡tico a los datos reservados para estudiar la capacidad predictiva del 
## modelo, se obtiene la matriz de confusiÃ³n, donde se observa que no se mejoran 
## los resultados respecto al discriminante lineal.

predicciones_qda <- modelo_qda |> predict(test)
matriz_confusion <- table(test$Species, predicciones_qda$class, dnn = c("Grupo real", "Grupo pronosticado"))
matriz_confusion <- reshape2::melt(matriz_confusion)
matriz_confusion <- caret::confusionMatrix(test$Species, predicciones_qda$class)
